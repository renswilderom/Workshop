{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "\n",
    "# Data science for social scientist\n",
    "## A friendly introduction to some powerfull tools\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![mario](http://i.imgur.com/0QZUW.jpg, width=600, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Content mini-workshop:\n",
    "\n",
    "* **Demonstration: data science applied to my own research**\n",
    "* **Lession 1:     regular expressions**\n",
    "* **Exercise 1:    develop your own regex pattern and erase centuries from a text**\n",
    "* **Create a dataset: run the demonstration code yourself so we have data for the following steps**\n",
    "* **Lession 2:     using Pandas for your SQL jobs and make more data from data**\n",
    "* **Exercise 2:**\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Demonstration: splitting and cleaning 'raw' newspaper articles\n",
    "\n",
    "Split batches of 200 articles downloaded from Lexis Nexis into seperate .txt files\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Lesson 1: regular expressions\n",
    "\n",
    "Regular expressions (regex in short) are very helpfull to clean and organize data. For example, to delete each digit a dataset, or each alphabetic character. Or to search for postal codes, telephone numbers, email addresses, specific words, or sentences. In those cases you can use a regex to find this particular sequence of characters and then do something with it.\n",
    "<br />\n",
    "<br />\n",
    "To run the code below, click in the cell, and hit Cntrl-Enter. \n",
    "To create a new cell, go to Insert in the menu above. Or click in an existing cell, and use Esc-B to create a new cell below. \n",
    "See 'More resources' in the bottom of this Notebook for other shortcuts.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Before you start, specify in which directory you work\n",
    "# Use the folder where the data (allarticles_merged.txt) is stored on your computer. \n",
    "# Don't put anything else in this folder.\n",
    "\n",
    "import os\n",
    "os.chdir('C:/Users/renswilderom/Documents/test')\n",
    "path = 'C:/Users/renswilderom/Documents/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mario is found! \n",
      "\n",
      "Group 1: \n",
      " For example, we are only interested in the text after a certain key word, say \n",
      "Group 2: \n",
      "  This information is super relevant.\n"
     ]
    }
   ],
   "source": [
    "# This example uses regex to split a text in two groups\n",
    "# It is based on a regex tutorial below (see 'More resources')\n",
    "\n",
    "import re\n",
    "\n",
    "line = \"For example, we are only interested in the text after a certain key word, say Mario. This information is super relevant.\"\n",
    "\n",
    "match = re.match('(.*)Mario.?(.*)', line) \n",
    "# By using the '?' symbol, the '.' after Mario becomes optional, so the pattern will match both 'Mario' and 'Mario.'\n",
    "\n",
    "if match:\n",
    "   print(\"Mario is found! \\n\") \n",
    "   print(\"Group 1: \\n\", match.group(1))  \n",
    "   print(\"Group 2: \\n\", match.group(2))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This information is super relevant.\n"
     ]
    }
   ],
   "source": [
    "# rather than grouping your data, you can also just delete the irrelevant parts:\n",
    "\n",
    "import re # like in the cell above, first import the regex module\n",
    "\n",
    "line = \"For example, we are only interested in the text after a certain key word, say Mario. This information is super relevant.\"\n",
    "\n",
    "print(re.sub('(.*?)Mario.', '', line)) # this pattern matches on 'Mario.' and anything before it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " This information is super relevant.\n"
     ]
    }
   ],
   "source": [
    "# you can also make a new value (or variable) called 'new_line'\n",
    "\n",
    "import re \n",
    "\n",
    "line = \"For example, we are only interested in the text after a certain key word, say Mario. This information is super relevant.\"\n",
    "\n",
    "new_line = re.sub('(.*?)Mario.', '', line) # this pattern matches on 'Mario.' and anything before it.\n",
    "\n",
    "print(new_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Instead of searching for specific words, like 'Mario', its also possible to search for any string consisting of five characters. Or anything which looks like an email address. Then you may also use special regex codes. For example, `\\d` will match on any digit, `\\D` any non-digit, and `\\w` matches both alphabetic characters and digits. \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  six seven\n",
      "4444 55555  \n",
      "4444  six \n"
     ]
    }
   ],
   "source": [
    "# Here is an example of how to use them:\n",
    "\n",
    "line = \"4444 55555 six seven\"\n",
    "\n",
    "print(re.sub('\\d', '', line)) # yields everything but digits\n",
    "print(re.sub('(?!\\s)\\D', '', line)) # yields digits (note that (?!\\s) does not matches on spaces, this is a 'negative look ahead') \n",
    "print(re.sub('\\w{5}', '', line)) # yields everything but five character strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "See also this comprehensive cheat sheat: http://www.rexegg.com/regex-quickstart.html\n",
    "<br />\n",
    "And here are the basic codes:\n",
    "<br />\n",
    "\\d  <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Matches digit  <br />\n",
    "\\D  <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Matches non-digit  <br />\n",
    "\\s  <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Matches whitespace  <br />\n",
    "\\S  <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Matches non-whitespace  <br />\n",
    "\\w  <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Matches alphanumeric  <br />\n",
    "\\W  <br />\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Matches non-alphanumeric <br />\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Exercise 1: regular expressions\n",
    "\n",
    "Please complete exercise A, B, and C below.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A: print the line without any references to centuries (e.g. 16th century needs to be omitted from the line) \n",
    "# B: print without punctuation (use the world wide web to find out how).\n",
    "# C: Do both A and B at once and save the output as a .txt file on your computer (use the world wide web to find out how).\n",
    "\n",
    "# And I will be there to help!\n",
    "\n",
    "import re\n",
    "\n",
    "# from Wikipedia on the history of pizza\n",
    "line = \"The innovation that led to flat bread pizza was the use of tomato as a topping. For some time after the tomato was brought to Europe from the Americas in the 16th century, it was believed by many Europeans to be poisonous (as some other fruits of the nightshade family are). However, by the late 18th century, it was common for the poor of the area around Naples to add tomato to their yeast-based flat bread, and so the pizza began.[citation needed] The dish gained popularity, and soon pizza became a tourist attraction as visitors to Naples ventured into the poorer areas of the city to try the local specialty. Antica Pizzeria Port'Alba in Naples Until about 1830, pizza was sold from open-air stands and out of pizza bakeries, and pizzerias keep this old tradition alive today. It is possible to enjoy paper-wrapped pizza and a drink sold from open-air stands outside the premises. Antica Pizzeria Port'Alba in Naples is widely regarded as the city's first pizzeria.[21] Purists, like the famous pizzeria 'Da Michele' in Via C. Sersale (founded 1870),[22] consider there to be only two true pizzas—the marinara and the margherita—and that is all they serve. Bamberger, David; Eban, Abba Solomon (1979). My People: Abba Eban's History of the Jews, Volume 2. Behrman House. p. 228. ISBN 0874412803. ‘Food and Drink - Pide - HiTiT Turkey guide’ Hitit.co.uk. Retrieved 2009-06-05. ‘History of Pizza Margherita’. tobetravelagent.com. 2012-04-09. Retrieved 2012-04-09.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "***\n",
    "\n",
    "## Create a dataset: run the demonstration code yourself so we have data for the following steps\n",
    "\n",
    "\n",
    "The loop below uses`(.*\\d+\\sof\\s\\d+\\sDOCUMENTS)` to search for a common delimiter (e.g.'1 of 200 DOCUMENTS') in between every newspaper article. Then the code opens a new file, called 'article', and writes the relevant information to it. \n",
    "<br />\n",
    "<br />\n",
    "I merged 15 of these 'batches' of Lexis Nexis articles together in one .txt file (allarticles_merged.txt). \n",
    "\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm done with splitting the files!\n",
      "The dataset is ready\n"
     ]
    }
   ],
   "source": [
    "import os, os.path, glob, re \n",
    "from shutil import move\n",
    "\n",
    "text_file = open(\"allarticles_merged.txt\",\"r\")\n",
    "lines = text_file.readlines()\n",
    "k = 1\n",
    "target = open(\"article\" + str(k) + \".txt\", \"a\")\n",
    "delimiterFound = False\n",
    "import re\n",
    "\n",
    "for line in lines :\n",
    "    k += 1\n",
    "    line = line.lstrip() #Removes blank lines and lead blank spaces\n",
    "    if delimiterFound == False:        \n",
    "            m = re.search('(.*\\d+\\sof\\s\\d+\\sDOCUMENTS)', line)\n",
    "            if m:\n",
    "                delimiterFound = True         \n",
    "                target.write(line)\n",
    "                target = open(\"article\" + str(k) + \".txt\", \"a\")\n",
    "            else:\n",
    "                target.write(line)             \n",
    "            \n",
    "    if delimiterFound == True:\n",
    "            m = re.search('(.*\\d+\\sof\\s\\d+\\sDOCUMENTS)', line)\n",
    "            if m:\n",
    "                delimiterFound = False\n",
    "                target.write(line)\n",
    "                target = open(\"article\" + str(k) + \".txt\", \"a\")\n",
    "            else:\n",
    "                target.write(line)  \n",
    "        \n",
    "target.close()\n",
    "text_file.close()\n",
    "os.remove(\"allarticles_merged.txt\") # this deletes it from your computer, so make a back up before running the code.\n",
    "print(\"I'm done with splitting the files!\")\n",
    "print(\"The dataset is ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You now have a csv dataset, its in the bottom of your working directory\n"
     ]
    }
   ],
   "source": [
    "# Write all the articles (stored as seperate .txt files) to one csv file \n",
    "\n",
    "# https://stackoverflow.com/questions/41913147/combine-a-folder-of-text-files-into-a-csv-with-each-content-in-a-cell\n",
    "\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "with open('newspaper_articles.csv', 'w', encoding='UTF-8', newline='') as out_file:\n",
    "    csv_out = csv.writer(out_file)\n",
    "    csv_out.writerow(['FileName', 'Content'])\n",
    "    for fileName in Path('.').glob('*.txt'):\n",
    "        lines = [ ]\n",
    "        with open(str(fileName.absolute()),'rb') as one_text:\n",
    "            for line in one_text.readlines():\n",
    "                lines.append(line.decode(encoding='UTF-8',errors='ignore').strip())\n",
    "        csv_out.writerow([str(fileName),' '.join(lines)])\n",
    "print(\"You now have a csv dataset, its in the bottom of your working directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article1.txt</th>\n",
       "      <td>BYLINE: From MARK TRAN LENGTH: 224 words DATEL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100044.txt</th>\n",
       "      <td>88 of 200 DOCUMENTS The Guardian (London) May ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100080.txt</th>\n",
       "      <td>89 of 200 DOCUMENTS The Guardian (London) Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100447.txt</th>\n",
       "      <td>90 of 200 DOCUMENTS The Guardian (London) Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100510.txt</th>\n",
       "      <td>91 of 200 DOCUMENTS The Guardian (London) Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article1011.txt</th>\n",
       "      <td>13 of 173 DOCUMENTS The Guardian (London) Nove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101215.txt</th>\n",
       "      <td>92 of 200 DOCUMENTS The Guardian (London) Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101282.txt</th>\n",
       "      <td>93 of 200 DOCUMENTS The Guardian (London) Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101346.txt</th>\n",
       "      <td>94 of 200 DOCUMENTS The Guardian (London) Apri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101425.txt</th>\n",
       "      <td>95 of 200 DOCUMENTS The Guardian (London) Apri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Content\n",
       "FileName                                                            \n",
       "article1.txt       BYLINE: From MARK TRAN LENGTH: 224 words DATEL...\n",
       "article100044.txt  88 of 200 DOCUMENTS The Guardian (London) May ...\n",
       "article100080.txt  89 of 200 DOCUMENTS The Guardian (London) Apri...\n",
       "article100447.txt  90 of 200 DOCUMENTS The Guardian (London) Apri...\n",
       "article100510.txt  91 of 200 DOCUMENTS The Guardian (London) Apri...\n",
       "article1011.txt    13 of 173 DOCUMENTS The Guardian (London) Nove...\n",
       "article101215.txt  92 of 200 DOCUMENTS The Guardian (London) Apri...\n",
       "article101282.txt  93 of 200 DOCUMENTS The Guardian (London) Apri...\n",
       "article101346.txt  94 of 200 DOCUMENTS The Guardian (London) Apri...\n",
       "article101425.txt  95 of 200 DOCUMENTS The Guardian (London) Apri..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the csv again as a Pandas 'data frame' \n",
    "\n",
    "from pandas import DataFrame\n",
    "df = DataFrame.from_csv(\"newspaper_articles.csv\", encoding='UTF-8')\n",
    "df.shape\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FileName</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>article1.txt</th>\n",
       "      <td>: From   : 224 words :  America's already blea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100044.txt</th>\n",
       "      <td>88 of 200  The Guardian (London) May 10, 1996 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100080.txt</th>\n",
       "      <td>89 of 200  The Guardian (London) April 27, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100447.txt</th>\n",
       "      <td>90 of 200  The Guardian (London) April 27, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article100510.txt</th>\n",
       "      <td>91 of 200  The Guardian (London) April 26, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article1011.txt</th>\n",
       "      <td>13 of 173  The Guardian (London) November 11, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101215.txt</th>\n",
       "      <td>92 of 200  The Guardian (London) April 26, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101282.txt</th>\n",
       "      <td>93 of 200  The Guardian (London) April 25, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101346.txt</th>\n",
       "      <td>94 of 200  The Guardian (London) April 19, 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article101425.txt</th>\n",
       "      <td>95 of 200  The Guardian (London) April 16, 199...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Content\n",
       "FileName                                                            \n",
       "article1.txt       : From   : 224 words :  America's already blea...\n",
       "article100044.txt  88 of 200  The Guardian (London) May 10, 1996 ...\n",
       "article100080.txt  89 of 200  The Guardian (London) April 27, 199...\n",
       "article100447.txt  90 of 200  The Guardian (London) April 27, 199...\n",
       "article100510.txt  91 of 200  The Guardian (London) April 26, 199...\n",
       "article1011.txt    13 of 173  The Guardian (London) November 11, ...\n",
       "article101215.txt  92 of 200  The Guardian (London) April 26, 199...\n",
       "article101282.txt  93 of 200  The Guardian (London) April 25, 199...\n",
       "article101346.txt  94 of 200  The Guardian (London) April 19, 199...\n",
       "article101425.txt  95 of 200  The Guardian (London) April 16, 199..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you like to experiment more outside this class, its possible to use regex to clean the articles inside the data frame.\n",
    "# here is an example\n",
    "# remove all captitalized words from the column 'Content'.\n",
    "df['Content'] = df['Content'].str.replace(r'\\b[A-Z]+\\b', '')\n",
    "df[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## More resources:\n",
    "\n",
    "#### Notebook shortcuts: https://www.cheatography.com/weidadeyue/cheat-sheets/jupyter-notebook/pdf_bw/\n",
    "#### Regex tutorial: https://www.tutorialspoint.com/python/python_reg_expressions.htm\n",
    "#### Working with Markdown: http://datascience.ibm.com/blog/markdown-for-jupyter-notebooks-cheatsheet/\n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# draft\n",
    "# local <img src=\"mario.jpg\", width=800, height=800>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
